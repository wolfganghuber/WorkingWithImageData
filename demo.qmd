---
title: 'Working with Image Data'
subtitle: 'Based on <a href="https://www.huber.embl.de/msmb/11-chap.html">Chapter 11 of "Modern Statistics for Modern Biology"</a>'
author: Wolfgang Huber
date: 2023-03-23
date-format: iso
format:
  revealjs: 
    theme: wh.scss
    logo: fig/ukraine.png
    transition: slide
    scrollable: true
    slide-number: c/t
    show-slide-number: all
    auto-stretch: false
    code-line-numbers: false
    code-copy: true
    code-link: true
    code-block-bg: true
    code-block-border-left: "#31BAE9"
execute: 
  echo: true
  warning: true
  error: false
  message: false
slide-level: 1
---

# Reading and displaying an image

<!--Notes on the YAML header:
 - auto-stretch is a huge source of grief for slide layout, see https://quarto.org/docs/presentations/revealjs/advanced.html - stretch
-->


```{r}
#| label: setup
#| echo: false
knitr::opts_chunk$set(cache = TRUE, autodep = TRUE)
options(EBImage.display = "raster")
```

```{r}
#| label: read
library("EBImage")
idi = readImage("fig/Stamp_of_Ukraine_s1985.jpg")
display(idi)
```

# Algebraic computations 

```{r}
x = 1 - idi
display(x)
```

# Convert into a greyscale image

```{r}
#| label: greyscale
idigr = (idi[,,1] + idi[,,2] + idi[,,3]) / 3    # could use `apply`; this is a bit faster
colorMode(idigr) = "grayscale"
display(idigr)
```

# Histogram

```{r}
hist(idigr)
```

# Algebraic computations 

```{r}
x = idigr * 2
display(x)
```

# Computations. An image is just an array 

```{r}
x = idigr ^ (1/3)
display(x)
```

# Thresholding

```{r}
x = idigr > quantile(idigr, prob = 0.25)
display(x)
```

# Transpose

```{r}
x = transpose(idi)
display(x)
```

# Rotate

```{r}
x = EBImage::rotate(idi, angle = 30)
display(x)
```

# Translate

```{r}
x = translate(idi, v = c(40, 70))
display(x)
```

# Flip: vertical reflection

```{r}
x = flip(idi)
display(x)
```

# Flop: horizontal reflection

```{r}
x = flop(idi)
display(x)
```

# Subsetting ('cropping')

```{r}
m = idi[800:1000, 420:560, ]
display(m)
```

# Stitching

```{r}
#| label: stitching1
#| echo: false
# This code chunk produces 4 individual tiles from the big initial image
ukraine_joewdavies = readImage("fig/ukraine_joewdavis.jpg")
sx = dim(ukraine_joewdavies)[1] / 2
sy = dim(ukraine_joewdavies)[2] / 2
tiles = list(ukraine_joewdavies[     1:sx    ,      1:sy, ], 
             ukraine_joewdavies[(sx+1):(2*sx),      1:sy, ], 
             ukraine_joewdavies[     1:sx    , (sy+1):(2*sy), ], 
             ukraine_joewdavies[(sx+1):(2*sx), (sy+1):(2*sy), ])
for (i in seq(along = tiles))
  writeImage(tiles[[i]], files = file.path("fig", sprintf("tile%03d.tiff", i)))
```
```{r}
#| label: stitching2
files = dir("fig", pattern = "^tile.*.tiff$", full.names = TRUE)
files
tiles = lapply(files, readImage) 
tiles[[1]]
```
```{r}
#| label: stitching3
#| layout-nrow: 1
#| fig-width:  !expr dim(ukraine_joewdavies)[1] / 2000
#| fig-height: !expr dim(ukraine_joewdavies)[2] / 2000
for (x in tiles) display(x)
```

<font size=-2>Thanks to Joe Davies (@joewdavies) for providing the image.</font>

```{r}
#| label: stitching4
sx = dim(tiles[[1]])[1]    # in practice, look at all tiles and do the gymnastics as necessary  
sy = dim(tiles[[1]])[2]    
combined = Image(NA_real_, dim = c(2 * sx, 2 * sy, 3), colormode = "color")
combined[     1:sx    ,      1:sy,     ] = tiles[[1]] 
combined[(sx+1):(2*sx),      1:sy,     ] = tiles[[2]] 
combined[     1:sx    , (sy+1):(2*sy), ] = tiles[[3]]
combined[(sx+1):(2*sx), (sy+1):(2*sy), ] = tiles[[4]]
display(combined)
```

# Segmentation, object feature extraction and classification

Read an image

```{r}
#| label: grusread
grus = readImage("fig/Grus_grus_flocks.jpg")  # common crane (Kranich, кран). Source: Wikipedia
display(grus)
```

Intensity histogram, by color (RGB)

```{r}
#| label: grushist
hist(grus)
```

Very simple segmentation: every pixel that's not very blue is a bird pixel

```{r}
#| label: grusseg
fg = (grus[,,3] < 0.7) 
colorMode(fg) = "grayscale"
display(fg)
```

Find connected components. Intention: each is a separate object of interest (i.e., a bird)

```{r}
#| label: grusconncomp
connCompID = bwlabel(fg)
display(colorLabels(connCompID))
```

Some heads are cut off due to misclassification of bright-colored neck as sky $\to$ small objects.
Refine: eliminate such small objects. Bird bodies without necks and heads are good enough for us, for now.

```{r}
#| label: grusconncomphist
connCompSize = table(connCompID) 
connCompSize
hist(sqrt(connCompSize[-1]), breaks = 25)

bad = names(connCompSize)[connCompSize < 4]
bad
connCompID[ connCompID %in% as.integer(bad) ] = 0L
display(colorLabels(connCompID))
```

Count the number of birds. (Object "0" is the sky.)

```{r}
#| label: numbirds
ids = unique(as.vector(connCompID)) |> setdiff("0")
length(ids)
```

Extract their coordinates (center of mass), and any other statistic we might care about.

```{r}
#| label: coords
#| warning: false
library("dplyr")
birds = lapply(ids, function(i) {
  w = which(connCompID == as.integer(i), arr.ind = TRUE)
  tibble(
    x = mean(w[, 1]), 
    y = mean(w[, 2]), 
    size = nrow(w),
    phi = prcomp(w)$rotation[,1] |> (\(x) atan(x[1] / x[2]))())
}) |> bind_rows() 
birds[1:3, ]
```

```{r}
#| label: beyonce
#| echo: false
if (!("beyonce" %in% installed.packages()[, 1])) devtools::install_github("dill/beyonce")
```

```{r}
#| label: plotcoords
library("ggplot2")
library("beyonce")
ggplot(birds, aes(x = x, y = -y, col = sqrt(size))) + geom_point() +
  scale_color_gradientn(colors = beyonce_palette(72, 21, type = "continuous")) + coord_fixed()
```

# Optical flow analysis on a movie of bird murmuration

This video is by dylan.winter@virgin.net, and I got it via Youtube. 

{{< video resources/eakKfY5aHmY.mp4 >}}

Use `ffmpeg` to extract the individual frames from time period 1:35 - 1:57 and store them as `png` files. 

```{sh}
#| label: ffmpegdisassemble
#| eval: FALSE
ffmpeg -ss 00:01:35 -t 00:01:57 -i resources/eakKfY5aHmY.mp4 frames/murm-%04d.png
```

Use `EBImage::readImages` to read into 4D array: $n_x\times n_y\times n_{\text{colors}}\times n_{\text{timepoints}}$.

```{r}
#| label: readmovie1
#| eval: FALSE
library("EBImage")
frames = dir("frames", full.names = TRUE) 
mov = readImage(frames[1:500])   # only 1:500 to save time/space, good enough for demo
dim(mov)
# [1]  1280  720    3  500
```

Apply [Optical Flow](https://en.wikipedia.org/wiki/Optical_flow)---basically, simple linear algebra / analysis---to detect and measure local velocities of image content

{{< video resources/murmuration-flow.mp4 >}}

The full code:

```{sh}
#| label: youtube-dl
#| eval: FALSE
# I first tried to download the video file with
youtube-dl "https://www.youtube.com/watch?v=eakKfY5aHmY"  
# but this resulted in the error message also reported here https://stackoverflow.com/questions/75495800/error-unable-to-extract-uploader-id-youtube-discord-py
# So I followed the top-voted reply there, and ran 
python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz
yt-dlp "https://www.youtube.com/watch?v=eakKfY5aHmY"

# The video has 25 frames per second. Some of the interesting segments are: 0:18-0:31, 1:21-1:33, 1:34-1:57, 2:10-2:32, 3:34-3:46
# I used the following to extract the frames from time period 1:35 - 1:57.
ffmpeg -ss 00:01:35 -t 00:01:57 -i resources/eakKfY5aHmY.mp4 frames/murm-%04d.png
```

Read the frames (`png` files) produced by `ffmpeg`

```{r}
#| label: readmovie2
#| eval: FALSE
library("EBImage")
frames = dir("frames", full.names = TRUE) 
frames = frames[1:500]
mov = readImage(frames)
print(object.size(mov), unit = "Gb")
movg = mov[,,1,] + mov[,,2,] + mov[,,3,]
colorMode(movg) = "grayscale"
```

Optical flow analysis: manually divide the image into overlapping squares on a grid, centered around `cx`, `cy`, of side length `2*epsilon`. Within each of them, for each time point, compute the flow vector `fvec`.

```{r}
#| label: Opticalflow
#| eval: FALSE
stride = 30
epsilon = 40
time = 1:dim(mov)[4]
# Instead of the 3 nested loops and fvec array, could also also use dplyr and a tidy tibble, depending on taste.  
cx = seq(from = epsilon, to = dim(movg)[1] - epsilon, by = stride)
cy = seq(from = epsilon, to = dim(movg)[2] - epsilon, by = stride)
fvec = array(NA_real_, dim = c(4, length(cx), length(cy), length(time) - 1))
for(it in seq_len(length(time) - 1)) {
  im1 = movg[, , time[it]    ]
  im2 = movg[, , time[it] + 1]
  for(ix in seq(along = cx)) {
    sx = (cx[ix] - epsilon + 1):(cx[ix] + epsilon)
    for(iy in seq(along = cy)) {
      sy = (cy[iy] - epsilon + 1):(cy[iy] + epsilon)
      xc = imagefx::xcorr3d(im1[ sx, sy], im2[ sx, sy])
      fvec[, ix, iy, it] = with(xc, c(max.shifts, max.corr, corr.mat[nrow(corr.mat)/2+1, ncol(corr.mat)/2+1]))
    }
  }
}
```

Save each frame as a PNG.

```{r}
#| label: Saveopticalflow
#| eval: FALSE
scala = 3
for(it in seq_len(length(time) - 1)) {
  png(file.path("opticalflow", sprintf("murm-%04d.png", it)), width = dim(mov)[1], height = dim(mov)[2], units = "px") 
  display(mov[,,,time[it]], method = "raster")
  for(ix in seq(along = cx)) 
    for(iy in seq(along = cy)) 
      if (is.finite(fvec[3, ix, iy, it]) && (fvec[3, ix, iy, it] > 0.5) && any(fvec[1:2, ix, iy, it] != 0))
        arrows(x0 = cx[ix], x1 = cx[ix] + scala * fvec[1, ix, iy, it], 
               y0 = cy[iy], y1 = cy[iy] + scala * fvec[2, ix, iy, it], 
               col = "#FFDD00", lwd = 2, length = 0.04)
  dev.off()
}
```

Assemble into a movie using `ffmpeg`.

```{sh}
#| label: ffmpegassemble
#| eval: FALSE
ffmpeg -framerate 12 -pattern_type glob -i 'opticalflow/*.png' -c:v libx264 -pix_fmt yuv420p resources/murmuration-flow.mp4 
```
